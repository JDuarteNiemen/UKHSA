{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DIY Disease Tracking Dashboard Kit](https://github.com/fsmeraldi/diy-covid19dash) (C) Fabrizio Smeraldi, 2020,2024 ([f.smeraldi@qmul.ac.uk](mailto:f.smeraldi@qmul.ac.uk) - [web](http://www.eecs.qmul.ac.uk/~fabri/)). This notebook is released under the [GNU GPLv3.0 or later](https://www.gnu.org/licenses/)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Covid-19 Deaths Across London Boroughs (2021–2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart shows the number of Covid-19 related deaths recorded in each of London’s 32 boroughs between January 2021 and December 2023.\n",
    "Each line represents one borough, allowing for comparison of how mortality trends evolved across different areas during this period.\n",
    "\n",
    "Following the severe impact of early 2021, most boroughs saw a decline in Covid-related deaths as vaccination rates increased and public health measures took effect. However, small fluctuations remained, reflecting local outbreaks and seasonal variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import ipywidgets as wdg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# make figures larger\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "class APIwrapper:\n",
    "    # class variables shared among all instances\n",
    "    _access_point=\"https://api.ukhsa-dashboard.data.gov.uk\"\n",
    "    _last_access=0.0 # time of last api access\n",
    "    \n",
    "    def __init__(self, theme, sub_theme, topic, geography_type, geography, metric):\n",
    "        \"\"\" Init the APIwrapper object, constructing the endpoint from the structure\n",
    "        parameters \"\"\"\n",
    "        # build the path with all the required structure parameters. You do not need to edit this line,\n",
    "        # parameters will be replaced by the actual values when you instantiate an object of the class!\n",
    "        url_path=(f\"/themes/{theme}/sub_themes/{sub_theme}/topics/{topic}/geography_types/\" +\n",
    "                  f\"{geography_type}/geographies/{geography}/metrics/{metric}\")\n",
    "        # our starting API endpoint\n",
    "        self._start_url=APIwrapper._access_point+url_path\n",
    "        self._filters=None\n",
    "        self._page_size=-1\n",
    "        # will contain the number of items\n",
    "        self.count=None\n",
    "\n",
    "    def get_page(self, filters={}, page_size=5):\n",
    "        \"\"\" Access the API and download the next page of data. Sets the count\n",
    "        attribute to the total number of items available for this query. Changing\n",
    "        filters or page_size will cause get_page to restart from page 1. Rate\n",
    "        limited to three request per second. The page_size parameter sets the number\n",
    "        of data points in one response page (maximum 365); use the default value \n",
    "        for debugging your structure and filters. \"\"\"\n",
    "        # Check page size is within range\n",
    "        if page_size>365:\n",
    "            raise ValueError(\"Max supported page size is 365\")\n",
    "        # restart from first page if page or filters have changed\n",
    "        if filters!=self._filters or page_size!=self._page_size:\n",
    "            self._filters=filters\n",
    "            self._page_size=page_size\n",
    "            self._next_url=self._start_url\n",
    "        # signal the end of data condition\n",
    "        if self._next_url==None: \n",
    "            return [] # we already fetched the last page\n",
    "        # simple rate limiting to avoid bans\n",
    "        curr_time=time.time() # Unix time: number of seconds since the Epoch\n",
    "        deltat=curr_time-APIwrapper._last_access\n",
    "        if deltat<0.33: # max 3 requests/second\n",
    "            time.sleep(0.33-deltat)\n",
    "        APIwrapper._last_access=curr_time\n",
    "        # build parameter dictionary by removing all the None\n",
    "        # values from filters and adding page_size\n",
    "        parameters={x: y for x, y in filters.items() if y!=None}\n",
    "        parameters['page_size']=page_size\n",
    "        # the page parameter is already included in _next_url.\n",
    "        # This is the API access. Response is a dictionary with various keys.\n",
    "        # the .json() method decodes the response into Python object (dictionaries,\n",
    "        # lists; 'null' values are translated as None).\n",
    "        response = requests.get(self._next_url, params=parameters).json()\n",
    "        # update url so we'll fetch the next page\n",
    "        self._next_url=response['next']\n",
    "        self.count=response['count']\n",
    "        # data are in the nested 'results' list\n",
    "        return response['results'] \n",
    "\n",
    "    def get_all_pages(self, filters={}, page_size=365):\n",
    "        \"\"\" Access the API and download all available data pages of data. Sets the count\n",
    "        attribute to the total number of items available for this query. API access rate\n",
    "        limited to three request per second. The page_size parameter sets the number\n",
    "        of data points in one response page (maximum 365), and controls the trade-off\n",
    "        between time to load a page and number of pages; the default should work well \n",
    "        in most cases. The number of items returned should in any case be equal to \n",
    "        the count attribute. \"\"\"\n",
    "        data=[] # build up all data here\n",
    "        while True:\n",
    "            # use get_page to do the job, including the pacing\n",
    "            next_page=self.get_page(filters, page_size)\n",
    "            if next_page==[]:\n",
    "                break # we are done\n",
    "            data.extend(next_page)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the url structure to access data\n",
    "london_structure={\"theme\": \"infectious_disease\", \n",
    "           \"sub_theme\": \"respiratory\",\n",
    "           \"topic\": \"COVID-19\",\n",
    "           \"geography_type\": \"Lower%20Tier%20Local%20Authority\"}\n",
    "\n",
    "#Creating list of all london boroughs to be added to url structure\n",
    "borough_list=[\"Barking%20and%20Dagenham\",\"Barnet\",\"Bexley\",\"Brent\",\"Bromley\",\"Camden\",\"City%20of%20London\",\"Croydon\",\"Ealing\",\"Enfield\",\"Greenwich\",\"Hackney\",\"Hammersmith%20and%20Fulham\",\"Haringey\",\n",
    "    \"Harrow\",\"Havering\",\"Hillingdon\",\"Hounslow\",\"Islington\",\"Kensington%20and%20Chelsea\",\"Kingston%20upon%20Thames\",\"Lambeth\",\"Lewisham\",\"Merton\",\"Newham\",\"Redbridge\",\"Richmond%20upon%20Thames\",\n",
    "    \"Southwark\",\"Sutton\",\"Tower%20Hamlets\",\"Waltham%20Forest\",\"Wandsworth\",\"Westminster\"]\n",
    "\n",
    "#Creating the list of metrics i want to look at\n",
    "metric_list=[\"COVID-19_cases_casesByDay\", \"COVID-19_deaths_ONSByWeek\"]\n",
    "\n",
    "for b in borough_list: \n",
    "        for m in metric_list:\n",
    "            london_structure[\"geography\"]=b\n",
    "            london_structure[\"metric\"]=m\n",
    "            api=APIwrapper(**london_structure)\n",
    "            ls=api.get_all_pages()\n",
    "            print(f\"Data points expected: {api.count}\")\n",
    "            print(f\"Data points retrieved: {len(ls)}\")\n",
    "        \n",
    "            with open(('data/' + b + '_' + m + '.json'), 'wt') as OUTF:\n",
    "                json.dump(ls, OUTF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this visualisation to:\n",
    "\n",
    "Identify boroughs with higher or lower mortality trends over time\n",
    "\n",
    "Observe overall declines following key public health interventions\n",
    "\n",
    "Compare how different parts of London were affected across pandemic phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON files and store the raw data in some variable. Edit as appropriate\n",
    "jsondata=os.listdir('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covid death data from 2019-12-30 00:00:00 to 2023-12-25 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120ee571a5dc4cfd9a03208f8ae1979a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(SelectMultiple(description='Boroughs:', index=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71fd0b695264c13b59f6392b9d36c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Copying borough list here for accessing files\n",
    "borough_list=[\"Barking%20and%20Dagenham\",\"Barnet\",\"Bexley\",\"Brent\",\"Bromley\",\"Camden\",\"City%20of%20London\",\"Croydon\",\"Ealing\",\"Enfield\",\"Greenwich\",\"Hackney\",\"Hammersmith%20and%20Fulham\",\"Haringey\",\n",
    "    \"Harrow\",\"Havering\",\"Hillingdon\",\"Hounslow\",\"Islington\",\"Kensington%20and%20Chelsea\",\"Kingston%20upon%20Thames\",\"Lambeth\",\"Lewisham\",\"Merton\",\"Newham\",\"Redbridge\",\"Richmond%20upon%20Thames\",\n",
    "    \"Southwark\",\"Sutton\",\"Tower%20Hamlets\",\"Waltham%20Forest\",\"Wandsworth\",\"Westminster\"]\n",
    "#Copying metric list to access files\n",
    "metric_list=[\"COVID-19_deaths_ONSByWeek\"]\n",
    "\n",
    "death_borough={} #Creating dictionary to store deaths for all boroughs\n",
    "\n",
    "\n",
    "for b in borough_list:\n",
    "        with open('data/' + b + '_COVID-19_deaths_ONSByWeek.json' , 'rt') as INFILE:\n",
    "            # case_borough[b]=json.load(INFILE)\n",
    "            file = json.load(INFILE)\n",
    "\n",
    "            ALL_DATA = []\n",
    "\n",
    "\n",
    "            #Creating a loop to get the date, metric and metric value for all the boroughs in covid deaths\n",
    "            for entry in file:\n",
    "                date=entry.get('date')\n",
    "                metric=entry.get('metric')\n",
    "                value=entry.get('metric_value')\n",
    "                \n",
    "                tup=(metric,value,date) \n",
    "                ALL_DATA.append(tup)\n",
    "                \n",
    "            death_borough[b]=ALL_DATA \n",
    "\n",
    "#Data is stored as a dictionary, every borough is a key, in which the values are a list of tuples containing the date and number of deaths\n",
    "\n",
    "#Removing duplicate week\n",
    "for b in death_borough:\n",
    "    if len(death_borough[b]) > 1 and death_borough[b][0] == death_borough[b][1]:\n",
    "        death_borough[b] = death_borough[b][1:]\n",
    "\n",
    "\n",
    "#Extracting data\n",
    "dates=[]\n",
    "for b in death_borough:\n",
    "\n",
    "    for t in death_borough[b]:\n",
    "        date=t[2]\n",
    "        if date not in dates:\n",
    "            dates.append(date)\n",
    "dates.sort()\n",
    "dates\n",
    "\n",
    "\n",
    "#Converting dates to panda types\n",
    "def parse_date(datestring):\n",
    "    \"\"\" Convert a date string into a pandas datetime object \"\"\"\n",
    "    return pd.to_datetime(datestring, format=\"%Y-%m-%d\")\n",
    "\n",
    "#Converting start and end dates to panda type\n",
    "startdate=parse_date(dates[0])\n",
    "enddate=parse_date(dates[-1])\n",
    "print('Covid death data from' ,startdate, 'to', enddate)\n",
    "\n",
    "#Define  DataFrame. Define the DateFrame by specifying its index and the title of its columns.\n",
    "index=pd.date_range(startdate, enddate, freq='W-MON')\n",
    "\n",
    "boroughtimeseriesdf=pd.DataFrame(index=index)\n",
    "\n",
    "\n",
    "\n",
    "#Creating loop to add all my boroughs to the graph\n",
    "for x, y in death_borough.items():\n",
    "    metric_list=[]\n",
    "    for t in y:\n",
    "        metrics =t[1]\n",
    "        metric_list.append(metrics)\n",
    "    boroughtimeseriesdf[x]=metric_list\n",
    "\n",
    "#fill in any remaining \"holes\" due to missing dates\n",
    "boroughtimeseriesdf.fillna(0.0, inplace=True)\n",
    "\n",
    "#Creating interactive plot\n",
    "\n",
    "series=wdg.SelectMultiple(\n",
    "    options=borough_list,\n",
    "    value=borough_list,\n",
    "    rows=5,\n",
    "    description='Boroughs:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "#Creating widget to set start date\n",
    "start_scale=wdg.DatePicker(\n",
    "    description='Start Date',\n",
    "    value=startdate,\n",
    "    disabled=False\n",
    ")\n",
    "#Creating widget to set end date\n",
    "end_scale=wdg.DatePicker(\n",
    "    description='End Date',\n",
    "    value=enddate,\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "reset_button = wdg.Button(\n",
    "    description='Reset dates',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to reset dates',\n",
    "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "\n",
    "def reset(x):\n",
    "        start_scale.value=startdate\n",
    "        end_scale.value=enddate\n",
    "\n",
    "reset_button.on_click(reset)\n",
    "\n",
    "controls=wdg.HBox([series, start_scale, end_scale, reset_button])\n",
    "\n",
    "\n",
    "def timeseries_graph(gcols, start_gscale, end_gscale):\n",
    "\n",
    "    ncols=len(gcols)\n",
    "    print(\"Click to select data for graph\")\n",
    "    print(\"(CTRL-Click to select more than one category)\")\n",
    "    ax=boroughtimeseriesdf[list(gcols)].plot(figsize=(13,5))\n",
    "    ax.set_xlim(xmin=start_gscale, xmax=end_gscale)\n",
    "    ax.set_title('Covid deaths across the London Boroughs');\n",
    "    ax.legend(prop={'size': 7}, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()  # adjusts plot to fit labels and legend\n",
    "    plt.show() # important - graphs won't update if this is missing\n",
    "\n",
    "# keep calling timeseries_graph(gcols=value_of_series, gscale=value_of_scale); \n",
    "# capture output in widget graph   \n",
    "graph=wdg.interactive_output(timeseries_graph, {'gcols': series, 'start_gscale':start_scale, 'end_gscale':end_scale})\n",
    "\n",
    "display(controls, graph)\n",
    "\n",
    "\n",
    "# putting the wrangling code into a function allows you to call it again after refreshing the data through \n",
    "# the API. You should call the function directly on the JSON data when the dashboard starts, by including \n",
    "# the call in this cell as below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source: Office for National Statistics (ONS), Covid-19 Mortality Data.\n",
    "Note: Values represent registered deaths involving Covid-19 and may be subject to revision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
